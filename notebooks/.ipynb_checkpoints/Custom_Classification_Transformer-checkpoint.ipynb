{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa36876f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.# All requested packages already installed.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.12.0\n",
      "  latest version: 23.3.1\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conda install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c923e215",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers import MultiHeadAttention, LayerNormalization, Dropout, Layer\n",
    "from keras.layers import Embedding, Input, GlobalAveragePooling1D, Dense\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb2ec081",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_block(embed_dim, num_heads, ff_dim, dropout_rate):\n",
    "    att = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "    ffn = Sequential(\n",
    "        [Dense(ff_dim, activation=\"relu\"),\n",
    "         Dense(embed_dim), ]\n",
    "    )\n",
    "    layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "    layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "    dropout1 = Dropout(dropout_rate)\n",
    "    dropout2 = Dropout(dropout_rate)\n",
    "    \n",
    "    def call(inputs, training):\n",
    "        attn_output = att(inputs, inputs)\n",
    "        attn_output = dropout1(attn_output, training=training)\n",
    "        out1 = layernorm1(inputs + attn_output)\n",
    "        ffn_output = ffn(out1)\n",
    "        ffn_output = dropout2(ffn_output, training=training)\n",
    "        return layernorm2(out1 + ffn_output)\n",
    "    \n",
    "    return call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f708c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "train_df = pd.read_csv('../data/tone_train.csv')\n",
    "x_train = np.array(train_df['numerical_sequence'].dropna().apply(lambda x: [int(i) for i in x.split(',')]).tolist())\n",
    "y_train = np.array(train_df['revised_BERT_sentiment_score'].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dce68a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "test_df = pd.read_csv('../data/tone_test.csv')\n",
    "x_test = np.array(test_df['numerical_sequence'].apply(lambda x: [int(i) for i in x.split(',')]).tolist())\n",
    "y_test = np.array(test_df['revised_BERT_sentiment_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d8a038a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad sequences to a fixed length\n",
    "maxlen = 227 # assuming the maximum sequence length is 200\n",
    "x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen, truncating='post')\n",
    "x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test, maxlen=maxlen, truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bba5afcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and validation split\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0e3317ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38217"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate x_train and x_test along the appropriate axis (assuming axis=0)\n",
    "x_combined = np.concatenate((x_train, x_test), axis=0)\n",
    "# Get the maximum value across all elements in the combined array\n",
    "vocab_size = np.max(x_combined) + 1\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0143a715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the EarlyStopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', \n",
    "                               # Number of epochs to wait for improvement\n",
    "                               patience=3,  \n",
    "                               verbose=1, \n",
    "                               # Restore the weights of the best epoch\n",
    "                               restore_best_weights=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6dd932a6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'KerasTensor' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [29]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m inputs \u001b[38;5;241m=\u001b[39m Input(shape\u001b[38;5;241m=\u001b[39m(max_seq_length,))\n\u001b[0;32m     10\u001b[0m embedding_layer \u001b[38;5;241m=\u001b[39m Embedding(input_dim\u001b[38;5;241m=\u001b[39mvocab_size, output_dim\u001b[38;5;241m=\u001b[39membedding_dim)(inputs)\n\u001b[1;32m---> 11\u001b[0m transformer_block_fn \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43membed_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mff_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mff_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mdropout_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropout_rate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m transformer_block \u001b[38;5;241m=\u001b[39m transformer_block_fn(embedding_layer, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     16\u001b[0m pooling_layer \u001b[38;5;241m=\u001b[39m GlobalAveragePooling1D()(transformer_block)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'KerasTensor' object is not callable"
     ]
    }
   ],
   "source": [
    "# define model architecture\n",
    "max_seq_length = x_train.shape[1]\n",
    "vocab_size = vocab_size\n",
    "embedding_dim = 16\n",
    "num_heads = 2\n",
    "ff_dim = 32\n",
    "dropout_rate = 0.3\n",
    "\n",
    "inputs = Input(shape=(max_seq_length,))\n",
    "embedding_layer = Embedding(input_dim=vocab_size, output_dim=embedding_dim)(inputs)\n",
    "transformer_block_fn = transformer_block(embed_dim=embedding_dim, \n",
    "                                         num_heads=num_heads, \n",
    "                                         ff_dim=ff_dim,\n",
    "                                        dropout_rate=dropout_rate)\n",
    "transformer_block = transformer_block_fn(embedding_layer, training=True)\n",
    "pooling_layer = GlobalAveragePooling1D()(transformer_block)\n",
    "dropout_layer = Dropout(dropout_rate)(pooling_layer)\n",
    "outputs = Dense(units=5, activation='softmax')(dropout_layer)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# train the model\n",
    "model.fit(x_train, y_train, batch_size=16, epochs=10, validation_data=(x_val, y_val),\n",
    "          callbacks=[early_stopping])\n",
    "\n",
    "# save the trained model\n",
    "model.save('../models/transformer_classification_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f7061ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('../models/transformer_classification_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b739dd",
   "metadata": {},
   "source": [
    "Do more epochs and get better accuracy\n",
    "Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "99ca71ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 2s 18ms/step - loss: 0.7625 - accuracy: 0.6787\n",
      "Validation loss: 0.7625349760055542\n",
      "Validation accuracy: 0.6787003874778748\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on validation data\n",
    "loss, accuracy = model.evaluate(x_val, y_val)\n",
    "print('Validation loss:', loss)\n",
    "print('Validation accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7660750",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
